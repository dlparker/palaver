
Commands et al

Currently mixing too many concepts. We have "alert" which is triggered by an attention phase. We also have "ScribeCommand"
which is currently only used to trigger the start and stop of text blocks, an ill defined concept. We have
recording blocks which are a capture window on audio data, other event data, and text, and are used to support
"rescan" to retry transcription via a better, slower model.

The "attention phrase" was introduced in order to avoid false positives in command phrase recognition. That is
still a good idea, but it should be decoupled from the nebulous text block concept and not depend on being
singular. In other words, you should be able to switch to command mode while inside a block, with these possible outcomes:

1. No new block is started if the command is standalone.
2. A new block is started otherwise, and the speaking context retains the fact
   that the new block was started while the other block was in flight.
3. A new blokc is started and it ends the previous block. This seems
   problematic as if requires that each block type (command?) be defined
   in a way that includes or precludes interleaving, subblocks, etc.
   Can't just be post edit because we don't know what to do when the
   nested block ends.
4. This seems like a stack, so many commands to manage stack?
    
 
The tension is between:

1. Making it easy and natural to talk to the system and get organized results
2. Making the code that does voice to text reliable and not excessively complex
3. Being able to provide handling instructions to the LLM that get it in the
   right frame of mind, which is probably specific to the point, focus, context,
   topic of the text.




Want a nested command logic, so probably a tree structure. Want some commands to have a block of text attached that
followed the command voicing, some should be standalone. When command end events get issued they should encapsulate
all the text blocks (if any) between the command start and end (if any). The start event should refer to a structure
that can have children, and the end should refer back to the start. Probably just a single structure and different
event types that refer to it, start event, end event, solo event .
   

Main architecture
1. [X] Move the recorder code out of the core and:
   1. [X] make it configurable
   2. [X] fix the listener name
   3. [X] Change it to store text blocks in directory
   4. [] Add logic to run_mic.py, playback.py, rescan.py ScribeAPIListener
      implementations to strip out attention phrases, block start phrases
      (needed info is in start block command) and end block phrases
   5. [] Add dynamic command loading code and call it during startup
   6. [] Add a DB for tracking, listing, deleteting, etc
   7. [] Add a method to add text revisions by ID (maybe using the json meta data)



OLD:

1. [X] The command detection is too stupid for words. Only needs a match on a single word. May have
   to use an actual prefix.


1. [X] Find a way to issue an end block command if audio ends with no command match. Probably should
   be in core, but implemented by command logic
2. [X] Change "Note" stuff to "Block"
3. [X] Build rescan support into recorder
4. [X] Add rescan using new storage

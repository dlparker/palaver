


1. Complete websocket draft add logic
2. Add "passive" mode to vtt_server.py where it expects to receive
   an url via web sockets to connect a NetListener to, then it
   initializes a NetListener and start is, tracks the calling
   connection and shuts down the NetListener on disconnect.
3. Build a test for vtt_server direct mode that works like
   mic mode test.
4. Update LLM review logic to work with new draft logic
5. Add pipemap registry that self constructs and provides
   urls for access to events and commands, extending existing catalog
6. Add VTT events to whisper
7. Maybe update all events to inlcude audio source info?
   If I use multiple mics this will probably be needed
   at some point. Easiest architecture for this is complete
   mutli-node pipeline for each audio source, but once
   draft is complete we still might want to know, might
   event want to have mute buttons for each audio source.

   
   
   
   

   
